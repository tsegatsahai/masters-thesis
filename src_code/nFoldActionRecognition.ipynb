{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d8b5ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.utils.np_utils.to_categorical(y, num_classes=None, dtype='float32')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "tf.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f57a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(#width_shift_range=0.1,\n",
    "                         #height_shift_range=0.1,\n",
    "                         #zoom_range=0.3,\n",
    "                         fill_mode='nearest',\n",
    "                         horizontal_flip = True)\n",
    "                         #rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4adc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc2d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "    # Here we say randomly turn off 50% of neurons.\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Last layer, not binary!\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', #not binary for the poses\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb5d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('classification_nfold.csv', dtype=str)\n",
    "#data = pd.read_csv('./Hand_Annotations_2.csv',dtype=str,names=colnames\n",
    "Y = train_data[['label']]\n",
    "\n",
    "# kf = KFold(n_splits = 3)\n",
    "                         \n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "image_shape = (150,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ce7f203",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 507 validated image filenames belonging to 3 classes.\n",
      "Found 57 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 32.6581 - accuracy: 0.4970\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70175, saving model to kfoldModels\\model_1.h5\n",
      "32/32 [==============================] - 37s 996ms/step - loss: 32.6581 - accuracy: 0.4970 - val_loss: 0.6605 - val_accuracy: 0.7018\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.7850\n",
      "Epoch 2: val_accuracy improved from 0.70175 to 0.80702, saving model to kfoldModels\\model_1.h5\n",
      "32/32 [==============================] - 31s 959ms/step - loss: 0.5867 - accuracy: 0.7850 - val_loss: 0.5973 - val_accuracy: 0.8070\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.8205\n",
      "Epoch 3: val_accuracy did not improve from 0.80702\n",
      "32/32 [==============================] - 30s 937ms/step - loss: 0.8642 - accuracy: 0.8205 - val_loss: 0.8729 - val_accuracy: 0.6842\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.8462\n",
      "Epoch 4: val_accuracy did not improve from 0.80702\n",
      "32/32 [==============================] - 31s 960ms/step - loss: 0.7605 - accuracy: 0.8462 - val_loss: 2.2166 - val_accuracy: 0.6491\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.8718\n",
      "Epoch 5: val_accuracy did not improve from 0.80702\n",
      "32/32 [==============================] - 27s 851ms/step - loss: 0.4956 - accuracy: 0.8718 - val_loss: 0.7010 - val_accuracy: 0.7895\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.4749 - accuracy: 0.8070\n",
      "Found 507 validated image filenames belonging to 3 classes.\n",
      "Found 57 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 35.9035 - accuracy: 0.4892\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66667, saving model to kfoldModels\\model_2.h5\n",
      "32/32 [==============================] - 39s 1s/step - loss: 35.9035 - accuracy: 0.4892 - val_loss: 0.7001 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.7298\n",
      "Epoch 2: val_accuracy improved from 0.66667 to 0.71930, saving model to kfoldModels\\model_2.h5\n",
      "32/32 [==============================] - 31s 977ms/step - loss: 0.6135 - accuracy: 0.7298 - val_loss: 0.7736 - val_accuracy: 0.7193\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.1532 - accuracy: 0.7436\n",
      "Epoch 3: val_accuracy improved from 0.71930 to 0.78947, saving model to kfoldModels\\model_2.h5\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.1532 - accuracy: 0.7436 - val_loss: 0.6750 - val_accuracy: 0.7895\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.8797\n",
      "Epoch 4: val_accuracy did not improve from 0.78947\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.3698 - accuracy: 0.8797 - val_loss: 0.9274 - val_accuracy: 0.7544\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.8935\n",
      "Epoch 5: val_accuracy improved from 0.78947 to 0.84211, saving model to kfoldModels\\model_2.h5\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3201 - accuracy: 0.8935 - val_loss: 0.6662 - val_accuracy: 0.8421\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.9320 - accuracy: 0.7895\n",
      "Found 507 validated image filenames belonging to 3 classes.\n",
      "Found 57 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 44.2579 - accuracy: 0.4970\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87719, saving model to kfoldModels\\model_3.h5\n",
      "32/32 [==============================] - 41s 1s/step - loss: 44.2579 - accuracy: 0.4970 - val_loss: 0.5143 - val_accuracy: 0.8772\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.7633\n",
      "Epoch 2: val_accuracy improved from 0.87719 to 0.89474, saving model to kfoldModels\\model_3.h5\n",
      "32/32 [==============================] - 31s 958ms/step - loss: 0.6034 - accuracy: 0.7633 - val_loss: 0.2993 - val_accuracy: 0.8947\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8383\n",
      "Epoch 3: val_accuracy did not improve from 0.89474\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4785 - accuracy: 0.8383 - val_loss: 1.2330 - val_accuracy: 0.7018\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8935\n",
      "Epoch 4: val_accuracy did not improve from 0.89474\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3281 - accuracy: 0.8935 - val_loss: 0.4643 - val_accuracy: 0.8246\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8955\n",
      "Epoch 5: val_accuracy improved from 0.89474 to 0.94737, saving model to kfoldModels\\model_3.h5\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3175 - accuracy: 0.8955 - val_loss: 0.2453 - val_accuracy: 0.9474\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.2437 - accuracy: 0.9298\n",
      "Found 507 validated image filenames belonging to 3 classes.\n",
      "Found 57 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 47.1473 - accuracy: 0.5385\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73684, saving model to kfoldModels\\model_4.h5\n",
      "32/32 [==============================] - 34s 887ms/step - loss: 47.1473 - accuracy: 0.5385 - val_loss: 0.5666 - val_accuracy: 0.7368\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7732\n",
      "Epoch 2: val_accuracy did not improve from 0.73684\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5715 - accuracy: 0.7732 - val_loss: 0.7903 - val_accuracy: 0.6842\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8402\n",
      "Epoch 3: val_accuracy did not improve from 0.73684\n",
      "32/32 [==============================] - 31s 980ms/step - loss: 0.4419 - accuracy: 0.8402 - val_loss: 1.0675 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.8797\n",
      "Epoch 4: val_accuracy improved from 0.73684 to 0.80702, saving model to kfoldModels\\model_4.h5\n",
      "32/32 [==============================] - 31s 969ms/step - loss: 0.3925 - accuracy: 0.8797 - val_loss: 0.6138 - val_accuracy: 0.8070\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9250\n",
      "Epoch 5: val_accuracy improved from 0.80702 to 0.82456, saving model to kfoldModels\\model_4.h5\n",
      "32/32 [==============================] - 31s 972ms/step - loss: 0.2248 - accuracy: 0.9250 - val_loss: 0.8773 - val_accuracy: 0.8246\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.9108 - accuracy: 0.7368\n",
      "Found 508 validated image filenames belonging to 3 classes.\n",
      "Found 56 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 17.2576 - accuracy: 0.5256\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78571, saving model to kfoldModels\\model_5.h5\n",
      "32/32 [==============================] - 42s 1s/step - loss: 17.2576 - accuracy: 0.5256 - val_loss: 0.5399 - val_accuracy: 0.7857\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7539\n",
      "Epoch 2: val_accuracy improved from 0.78571 to 0.87500, saving model to kfoldModels\\model_5.h5\n",
      "32/32 [==============================] - 31s 968ms/step - loss: 0.6457 - accuracy: 0.7539 - val_loss: 0.3586 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.8425\n",
      "Epoch 3: val_accuracy did not improve from 0.87500\n",
      "32/32 [==============================] - 30s 925ms/step - loss: 0.6381 - accuracy: 0.8425 - val_loss: 1.7136 - val_accuracy: 0.6250\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.8504\n",
      "Epoch 4: val_accuracy did not improve from 0.87500\n",
      "32/32 [==============================] - 31s 966ms/step - loss: 0.4233 - accuracy: 0.8504 - val_loss: 0.3745 - val_accuracy: 0.8393\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9094\n",
      "Epoch 5: val_accuracy did not improve from 0.87500\n",
      "32/32 [==============================] - 29s 915ms/step - loss: 0.2733 - accuracy: 0.9094 - val_loss: 0.5438 - val_accuracy: 0.8750\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.4213 - accuracy: 0.8393\n",
      "Found 508 validated image filenames belonging to 3 classes.\n",
      "Found 56 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 33.8637 - accuracy: 0.5728\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78571, saving model to kfoldModels\\model_6.h5\n",
      "32/32 [==============================] - 35s 931ms/step - loss: 33.8637 - accuracy: 0.5728 - val_loss: 0.5898 - val_accuracy: 0.7857\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.7972\n",
      "Epoch 2: val_accuracy did not improve from 0.78571\n",
      "32/32 [==============================] - 29s 890ms/step - loss: 0.5569 - accuracy: 0.7972 - val_loss: 0.5540 - val_accuracy: 0.7857\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.8091\n",
      "Epoch 3: val_accuracy did not improve from 0.78571\n",
      "32/32 [==============================] - 29s 896ms/step - loss: 0.5734 - accuracy: 0.8091 - val_loss: 0.3849 - val_accuracy: 0.7857\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.8602\n",
      "Epoch 4: val_accuracy improved from 0.78571 to 0.83929, saving model to kfoldModels\\model_6.h5\n",
      "32/32 [==============================] - 27s 857ms/step - loss: 0.4542 - accuracy: 0.8602 - val_loss: 0.5623 - val_accuracy: 0.8393\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9173\n",
      "Epoch 5: val_accuracy did not improve from 0.83929\n",
      "32/32 [==============================] - 25s 801ms/step - loss: 0.2738 - accuracy: 0.9173 - val_loss: 0.5957 - val_accuracy: 0.8393\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4500 - accuracy: 0.8571\n",
      "Found 508 validated image filenames belonging to 3 classes.\n",
      "Found 56 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 38.9148 - accuracy: 0.5453\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76786, saving model to kfoldModels\\model_7.h5\n",
      "32/32 [==============================] - 34s 933ms/step - loss: 38.9148 - accuracy: 0.5453 - val_loss: 0.5920 - val_accuracy: 0.7679\n",
      "Epoch 2/5\n",
      "10/32 [========>.....................] - ETA: 20s - loss: 0.6601 - accuracy: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# There can be other callbacks, but just showing one because it involves the model name\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# This saves the best model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# FIT THE MODEL\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch=150,\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#PLOT HISTORY\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# LOAD BEST MODEL to evaluate the performance of the model\u001b[39;00m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkfoldModels/model_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold_var)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = 'kfoldModels/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in skf.split(np.zeros(564),Y):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, target_size=image_shape[:2],\n",
    "                               batch_size = 16,\n",
    "                               x_col = \"filename\", y_col = \"label\",\n",
    "                               class_mode = \"categorical\", shuffle = True)\n",
    "    valid_data_generator  = idg.flow_from_dataframe(validation_data, target_size=image_shape[:2],\n",
    "                            batch_size = 16,\n",
    "                            x_col = \"filename\", y_col = \"label\",\n",
    "                            class_mode = \"categorical\", shuffle = True)\n",
    "    \n",
    "  \n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    model = create_new_model()\n",
    "\n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "                            monitor='val_accuracy', verbose=1, \n",
    "                            save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                epochs=5,\n",
    "                #steps_per_epoch=150,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=valid_data_generator)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    #PLOT HISTORY\n",
    "\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(\"kfoldModels/model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    \n",
    "    #calculate sensitivity and specificity \n",
    "    \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold_var += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
