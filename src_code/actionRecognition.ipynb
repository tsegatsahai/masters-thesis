{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for the model\n",
    "\n",
    "There is too much data for us to read all at once in memory. We can use some built in functions in Keras to automatically process the data, generate a flow of batches from a directory, and also manipulate the images.\n",
    "\n",
    "### Image Manipulation\n",
    "\n",
    "Its usually a good idea to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. We can use the **ImageDataGenerator** to do this automatically for us. Check out the documentation for a full list of all the parameters you can use here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(#rotation_range=30, # rotate the image 30 degrees\n",
    "                               #width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
    "                               #height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
    "                               rescale=1/255, # Rescale the image by normalzing it.\n",
    "                               #shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
    "                               #zoom_range=0.2, # Zoom in by 20% max\n",
    "                               horizontal_flip=True, # Allo horizontal flipping\n",
    "                               #fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 558 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.DirectoryIterator at 0x7feb54495a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_gen.flow_from_directory('positions/train')\n",
    "image_gen.flow_from_directory('actions/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.DirectoryIterator at 0x7feb58a4d710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen.flow_from_directory('actions/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Images\n",
    "\n",
    "Let's have Keras resize all the images to 150 pixels by 150 pixels once they've been manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width,height,channels\n",
    "image_shape = (150,150,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "# Here we say randomly turn off 50% of neurons.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Last layer, not binary!\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #not binary for the poses\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2367616   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,424,323\n",
      "Trainable params: 2,424,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 558 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory('actions/train',\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical') #catagoricalnfor the poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(train_image_gen))\n",
    "#train_image_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory('actions/test',\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fall': 0, 'onFeet': 1, 'sit': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 119s 796ms/step - loss: 0.4418 - acc: 0.8203 - val_loss: 0.5242 - val_acc: 0.8792\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 97s 646ms/step - loss: 0.1247 - acc: 0.9582 - val_loss: 0.5996 - val_acc: 0.8658\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 97s 647ms/step - loss: 0.0473 - acc: 0.9858 - val_loss: 0.7610 - val_acc: 0.8792\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 147s 979ms/step - loss: 0.0305 - acc: 0.9928 - val_loss: 0.7983 - val_acc: 0.8859\n",
      "Epoch 5/10\n",
      " 60/150 [===========>..................] - ETA: 1:01 - loss: 0.0065 - acc: 0.9990"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(train_image_gen,epochs=10,\n",
    "                              steps_per_epoch=150,\n",
    "                              validation_data=test_image_gen,\n",
    "                             validation_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8340300997862449,\n",
       " 0.9577405855745451,\n",
       " 0.9849624060150376,\n",
       " 0.9899581589958159,\n",
       " 0.9949832775919732,\n",
       " 0.9962374581939799,\n",
       " 0.999163179916318,\n",
       " 0.9974916387959866,\n",
       " 0.999163179916318,\n",
       " 0.9983277591973244]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e64fa3ef0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('binaryModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fall': 0, 'onFeet': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "pose_file = 'testing/walk5.jpg'\n",
    "\n",
    "pose = image.load_img(pose_file, target_size=(150, 150))\n",
    "\n",
    "pose = image.img_to_array(pose)\n",
    "\n",
    "pose = np.expand_dims(pose, axis=0) #so the network can think its a batch of one image\n",
    "pose = pose/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob = new_model.predict(pose)\n",
    "new_model.predict_classes(pose) \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7743273e-06 3.3431544e-07 1.8688984e-07 3.5053063e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Output prediction\n",
    "print(prediction_prob) #how sure is it that the image belongs to the array it chose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "#function to classify a pose\n",
    "def predictPose(imageName):\n",
    "    #resize the image since the model is trained with 150 by 150 images\n",
    "    pose = image.load_img(imageName, target_size=(150,150))\n",
    "    pose = image.img_to_array(pose)\n",
    "    pose = np.expand_dims(pose, axis=0)\n",
    "    pose = pose/255\n",
    "    \n",
    "    #actual classification\n",
    "    prediction_prob = new_model.predict(pose)\n",
    "    #returns which pose\n",
    "    poseNumber = new_model.predict_classes(pose)\n",
    "    #print(prediction_prob)\n",
    "    return poseNumber[0]+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllImages(rootdir):\n",
    "    \"\"\"Gets all of the images in a folder and runs them through OpenPose.\n",
    "    You just need to run this function with the folder of pose images\"\"\"\n",
    "    path, dirs, files = next(os.walk(rootdir))\n",
    "    file_count = len(files) - 1\n",
    "    poseList = []\n",
    "    action = 0\n",
    "    actionList = []\n",
    "    i = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            # print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + file\n",
    "\n",
    "            if filepath.endswith(\".jpg\"):\n",
    "                i += 1\n",
    "                #printProgressBar(i + 1, file_count, prefix='Progress:', suffix='Complete', length=50)\n",
    "                print(\"processing image \"+ str(filepath))\n",
    "                action = predictPose(filepath)\n",
    "                print(action)\n",
    "                actionList.append(action)\n",
    "    return actionList\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPercentage(catagory,result):\n",
    "    fall = 0\n",
    "    onFeet = 0\n",
    "    sit = 0\n",
    "    size = len(result)\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            fall += 1\n",
    "        elif i == 2:\n",
    "            onFeet += 1\n",
    "        elif i == 3:\n",
    "            sit += 1\n",
    "        else:\n",
    "            print(\"error\")\n",
    "    print('Result of', size, catagory, 'images')\n",
    "    print('fall:', fall, str((fall/size)*100)+'%')\n",
    "   # print('sit:', sit, str((sit/size)*100)+'%')\n",
    "    print('onFeet:', onFeet, str((onFeet/size)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time at start: 7.891654968261719e-05\n",
      "processing image testing/fall/77.jpg\n",
      "3\n",
      "processing image testing/fall/89.jpg\n",
      "1\n",
      "processing image testing/fall/62.jpg\n",
      "1\n",
      "processing image testing/fall/60.jpg\n",
      "2\n",
      "processing image testing/fall/48.jpg\n",
      "2\n",
      "processing image testing/fall/49.jpg\n",
      "2\n",
      "processing image testing/fall/59.jpg\n",
      "1\n",
      "processing image testing/fall/71.jpg\n",
      "1\n",
      "processing image testing/fall/64.jpg\n",
      "1\n",
      "processing image testing/fall/8.jpg\n",
      "1\n",
      "processing image testing/fall/66.jpg\n",
      "1\n",
      "processing image testing/fall/99.jpg\n",
      "1\n",
      "processing image testing/fall/98.jpg\n",
      "2\n",
      "processing image testing/fall/73.jpg\n",
      "1\n",
      "processing image testing/fall/67.jpg\n",
      "1\n",
      "processing image testing/fall/9.jpg\n",
      "1\n",
      "processing image testing/fall/14.jpg\n",
      "1\n",
      "processing image testing/fall/28.jpg\n",
      "1\n",
      "processing image testing/fall/101.jpg\n",
      "1\n",
      "processing image testing/fall/115.jpg\n",
      "1\n",
      "processing image testing/fall/17.jpg\n",
      "1\n",
      "processing image testing/fall/116.jpg\n",
      "1\n",
      "processing image testing/fall/103.jpg\n",
      "1\n",
      "processing image testing/fall/117.jpg\n",
      "3\n",
      "processing image testing/fall/16.jpg\n",
      "1\n",
      "processing image testing/fall/12.jpg\n",
      "1\n",
      "processing image testing/fall/113.jpg\n",
      "1\n",
      "processing image testing/fall/107.jpg\n",
      "1\n",
      "processing image testing/fall/106.jpg\n",
      "1\n",
      "processing image testing/fall/13.jpg\n",
      "1\n",
      "processing image testing/fall/39.jpg\n",
      "3\n",
      "processing image testing/fall/104.jpg\n",
      "1\n",
      "processing image testing/fall/111.jpg\n",
      "1\n",
      "processing image testing/fall/105.jpg\n",
      "1\n",
      "processing image testing/fall/10.jpg\n",
      "1\n",
      "processing image testing/fall/38.jpg\n",
      "1\n",
      "processing image testing/fall/21.jpg\n",
      "1\n",
      "processing image testing/fall/35.jpg\n",
      "1\n",
      "processing image testing/fall/108.jpg\n",
      "3\n",
      "processing image testing/fall/120.jpg\n",
      "1\n",
      "processing image testing/fall/109.jpg\n",
      "1\n",
      "processing image testing/fall/34.jpg\n",
      "1\n",
      "processing image testing/fall/20.jpg\n",
      "1\n",
      "processing image testing/fall/36.jpg\n",
      "1\n",
      "processing image testing/fall/122.jpg\n",
      "1\n",
      "processing image testing/fall/23.jpg\n",
      "1\n",
      "processing image testing/fall/26.jpg\n",
      "2\n",
      "processing image testing/fall/32.jpg\n",
      "1\n",
      "processing image testing/fall/30.jpg\n",
      "1\n",
      "processing image testing/fall/125.jpg\n",
      "1\n",
      "processing image testing/fall/119.jpg\n",
      "1\n",
      "processing image testing/fall/118.jpg\n",
      "1\n",
      "processing image testing/fall/31.jpg\n",
      "1\n",
      "processing image testing/fall/25.jpg\n",
      "1\n",
      "processing image testing/fall/19.jpg\n",
      "1\n",
      "processing image testing/fall/42.jpg\n",
      "2\n",
      "processing image testing/fall/4.jpg\n",
      "1\n",
      "processing image testing/fall/56.jpg\n",
      "1\n",
      "processing image testing/fall/81.jpg\n",
      "1\n",
      "processing image testing/fall/80.jpg\n",
      "1\n",
      "processing image testing/fall/5.jpg\n",
      "2\n",
      "processing image testing/fall/57.jpg\n",
      "1\n",
      "processing image testing/fall/43.jpg\n",
      "1\n",
      "processing image testing/fall/55.jpg\n",
      "1\n",
      "processing image testing/fall/7.jpg\n",
      "1\n",
      "processing image testing/fall/41.jpg\n",
      "1\n",
      "processing image testing/fall/96.jpg\n",
      "1\n",
      "processing image testing/fall/82.jpg\n",
      "1\n",
      "processing image testing/fall/83.jpg\n",
      "1\n",
      "processing image testing/fall/68.jpg\n",
      "1\n",
      "processing image testing/fall/40.jpg\n",
      "1\n",
      "processing image testing/fall/54.jpg\n",
      "1\n",
      "processing image testing/fall/6.jpg\n",
      "2\n",
      "processing image testing/fall/87.jpg\n",
      "1\n",
      "processing image testing/fall/45.jpg\n",
      "1\n",
      "processing image testing/fall/51.jpg\n",
      "1\n",
      "processing image testing/fall/79.jpg\n",
      "1\n",
      "processing image testing/fall/53.jpg\n",
      "1\n",
      "processing image testing/fall/1.jpg\n",
      "1\n",
      "processing image testing/fall/84.jpg\n",
      "1\n",
      "processing image testing/fall/90.jpg\n",
      "1\n",
      "processing image testing/fall/91.jpg\n",
      "1\n",
      "processing image testing/fall/52.jpg\n",
      "1\n",
      "Time taken: 3.1200180053710938\n"
     ]
    }
   ],
   "source": [
    "#testing falling\n",
    "t = time.time()\n",
    "print(\"Time at start: \" + str((time.time() - t)))\n",
    "fallingResult = getAllImages('testing/fall')\n",
    "print(\"Time taken: \" + str((time.time() - t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 100 falling images\n",
      "total: 100\n",
      "fall: 82 82.0\n",
      "sit: 10 10.0\n",
      "onFeet: 8 8.0\n"
     ]
    }
   ],
   "source": [
    "#displaying results of falling\n",
    "calcPercentage('falling', fallingResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 83 falling images\n",
      "fall: 71 85.54216867469879%\n",
      "sit: 4 4.819277108433735%\n",
      "onFeet: 8 9.63855421686747%\n"
     ]
    }
   ],
   "source": [
    "#displaying results of falling\n",
    "calcPercentage('falling', fallingResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time at start: 7.82012939453125e-05\n",
      "processing image testing/onFeet/63.jpg\n",
      "2\n",
      "processing image testing/onFeet/77.jpg\n",
      "1\n",
      "processing image testing/onFeet/162.jpg\n",
      "2\n",
      "processing image testing/onFeet/62.jpg\n",
      "2\n",
      "processing image testing/onFeet/60.jpg\n",
      "2\n",
      "processing image testing/onFeet/149.jpg\n",
      "2\n",
      "processing image testing/onFeet/161.jpg\n",
      "2\n",
      "processing image testing/onFeet/160.jpg\n",
      "2\n",
      "processing image testing/onFeet/148.jpg\n",
      "2\n",
      "processing image testing/onFeet/49.jpg\n",
      "2\n",
      "processing image testing/onFeet/61.jpg\n",
      "2\n",
      "processing image testing/onFeet/59.jpg\n",
      "2\n",
      "processing image testing/onFeet/71.jpg\n",
      "2\n",
      "processing image testing/onFeet/65.jpg\n",
      "2\n",
      "processing image testing/onFeet/158.jpg\n",
      "2\n",
      "processing image testing/onFeet/159.jpg\n",
      "2\n",
      "processing image testing/onFeet/64.jpg\n",
      "1\n",
      "processing image testing/onFeet/70.jpg\n",
      "2\n",
      "processing image testing/onFeet/58.jpg\n",
      "2\n",
      "processing image testing/onFeet/8.jpg\n",
      "2\n",
      "processing image testing/onFeet/66.jpg\n",
      "2\n",
      "processing image testing/onFeet/72.jpg\n",
      "2\n",
      "processing image testing/onFeet/73.jpg\n",
      "1\n",
      "processing image testing/onFeet/67.jpg\n",
      "2\n",
      "processing image testing/onFeet/9.jpg\n",
      "2\n",
      "processing image testing/onFeet/28.jpg\n",
      "2\n",
      "processing image testing/onFeet/29.jpg\n",
      "2\n",
      "processing image testing/onFeet/12.jpg\n",
      "2\n",
      "processing image testing/onFeet/13.jpg\n",
      "2\n",
      "processing image testing/onFeet/39.jpg\n",
      "2\n",
      "processing image testing/onFeet/11.jpg\n",
      "2\n",
      "processing image testing/onFeet/10.jpg\n",
      "2\n",
      "processing image testing/onFeet/38.jpg\n",
      "2\n",
      "processing image testing/onFeet/21.jpg\n",
      "2\n",
      "processing image testing/onFeet/35.jpg\n",
      "2\n",
      "processing image testing/onFeet/34.jpg\n",
      "2\n",
      "processing image testing/onFeet/20.jpg\n",
      "2\n",
      "processing image testing/onFeet/36.jpg\n",
      "2\n",
      "processing image testing/onFeet/22.jpg\n",
      "2\n",
      "processing image testing/onFeet/23.jpg\n",
      "2\n",
      "processing image testing/onFeet/33.jpg\n",
      "1\n",
      "processing image testing/onFeet/27.jpg\n",
      "2\n",
      "processing image testing/onFeet/32.jpg\n",
      "2\n",
      "processing image testing/onFeet/18.jpg\n",
      "2\n",
      "processing image testing/onFeet/24.jpg\n",
      "2\n",
      "processing image testing/onFeet/30.jpg\n",
      "3\n",
      "processing image testing/onFeet/31.jpg\n",
      "2\n",
      "processing image testing/onFeet/25.jpg\n",
      "2\n",
      "processing image testing/onFeet/19.jpg\n",
      "2\n",
      "processing image testing/onFeet/42.jpg\n",
      "2\n",
      "processing image testing/onFeet/56.jpg\n",
      "2\n",
      "processing image testing/onFeet/143.jpg\n",
      "2\n",
      "processing image testing/onFeet/157.jpg\n",
      "2\n",
      "processing image testing/onFeet/156.jpg\n",
      "2\n",
      "processing image testing/onFeet/80.jpg\n",
      "2\n",
      "processing image testing/onFeet/5.jpg\n",
      "2\n",
      "processing image testing/onFeet/57.jpg\n",
      "2\n",
      "processing image testing/onFeet/43.jpg\n",
      "2\n",
      "processing image testing/onFeet/55.jpg\n",
      "2\n",
      "processing image testing/onFeet/41.jpg\n",
      "2\n",
      "processing image testing/onFeet/69.jpg\n",
      "2\n",
      "processing image testing/onFeet/154.jpg\n",
      "2\n",
      "processing image testing/onFeet/155.jpg\n",
      "2\n",
      "processing image testing/onFeet/68.jpg\n",
      "2\n",
      "processing image testing/onFeet/40.jpg\n",
      "2\n",
      "processing image testing/onFeet/54.jpg\n",
      "2\n",
      "processing image testing/onFeet/6.jpg\n",
      "2\n",
      "processing image testing/onFeet/78.jpg\n",
      "2\n",
      "processing image testing/onFeet/2.jpg\n",
      "2\n",
      "processing image testing/onFeet/50.jpg\n",
      "2\n",
      "processing image testing/onFeet/44.jpg\n",
      "2\n",
      "processing image testing/onFeet/151.jpg\n",
      "2\n",
      "processing image testing/onFeet/145.jpg\n",
      "2\n",
      "processing image testing/onFeet/144.jpg\n",
      "2\n",
      "processing image testing/onFeet/150.jpg\n",
      "2\n",
      "processing image testing/onFeet/45.jpg\n",
      "2\n",
      "processing image testing/onFeet/3.jpg\n",
      "2\n",
      "processing image testing/onFeet/51.jpg\n",
      "2\n",
      "processing image testing/onFeet/79.jpg\n",
      "1\n",
      "processing image testing/onFeet/47.jpg\n",
      "2\n",
      "processing image testing/onFeet/53.jpg\n",
      "2\n",
      "processing image testing/onFeet/1.jpg\n",
      "1\n",
      "processing image testing/onFeet/146.jpg\n",
      "2\n",
      "processing image testing/onFeet/152.jpg\n",
      "2\n",
      "processing image testing/onFeet/147.jpg\n",
      "2\n",
      "processing image testing/onFeet/52.jpg\n",
      "2\n",
      "processing image testing/onFeet/46.jpg\n",
      "2\n",
      "Time taken: 3.9062321186065674\n"
     ]
    }
   ],
   "source": [
    "#testing onFeet\n",
    "t = time.time()\n",
    "print(\"Time at start: \" + str((time.time() - t)))\n",
    "onFeetResult = getAllImages('testing/onFeet')\n",
    "print(\"Time taken: \" + str((time.time() - t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 98 onFeet images\n",
      "total: 98\n",
      "fall: 11 11.224489795918368\n",
      "sit: 2 2.0408163265306123\n",
      "onFeet: 85 86.73469387755102\n"
     ]
    }
   ],
   "source": [
    "#displaying results of onFeet\n",
    "calcPercentage('onFeet', onFeetResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 87 onFeet images\n",
      "fall: 6 6.896551724137931%\n",
      "sit: 1 1.1494252873563218%\n",
      "onFeet: 80 91.95402298850574%\n"
     ]
    }
   ],
   "source": [
    "#displaying results of onFeet\n",
    "calcPercentage('onFeet', onFeetResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time at start: 7.772445678710938e-05\n",
      "processing image testing/sit/228.jpg\n",
      "3\n",
      "processing image testing/sit/214.jpg\n",
      "3\n",
      "processing image testing/sit/229.jpg\n",
      "3\n",
      "processing image testing/sit/217.jpg\n",
      "3\n",
      "processing image testing/sit/216.jpg\n",
      "3\n",
      "processing image testing/sit/212.jpg\n",
      "3\n",
      "processing image testing/sit/213.jpg\n",
      "3\n",
      "processing image testing/sit/211.jpg\n",
      "3\n",
      "processing image testing/sit/221.jpg\n",
      "3\n",
      "processing image testing/sit/222.jpg\n",
      "3\n",
      "processing image testing/sit/223.jpg\n",
      "3\n",
      "processing image testing/sit/227.jpg\n",
      "3\n",
      "processing image testing/sit/226.jpg\n",
      "3\n",
      "processing image testing/sit/230.jpg\n",
      "3\n",
      "processing image testing/sit/224.jpg\n",
      "3\n",
      "processing image testing/sit/218.jpg\n",
      "3\n",
      "processing image testing/sit/219.jpg\n",
      "3\n",
      "Time taken: 0.6856949329376221\n"
     ]
    }
   ],
   "source": [
    "#testing sitting\n",
    "t = time.time()\n",
    "print(\"Time at start: \" + str((time.time() - t)))\n",
    "sitResult = getAllImages('testing/sit')\n",
    "print(\"Time taken: \" + str((time.time() - t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 20 sitting images\n",
      "total: 20\n",
      "fall: 1 5.0\n",
      "sit: 18 90.0\n",
      "onFeet: 1 5.0\n"
     ]
    }
   ],
   "source": [
    "#displaying results of sitting\n",
    "calcPercentage('sitting', sitResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 17 sitting images\n",
      "fall: 0 0.0%\n",
      "sit: 17 100.0%\n",
      "onFeet: 0 0.0%\n"
     ]
    }
   ],
   "source": [
    "#displaying results of sitting\n",
    "calcPercentage('sitting', sitResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time at start: 5.1021575927734375e-05\n",
      "processing image testing/fall/77.jpg\n",
      "2\n",
      "processing image testing/fall/89.jpg\n",
      "1\n",
      "processing image testing/fall/62.jpg\n",
      "1\n",
      "processing image testing/fall/60.jpg\n",
      "2\n",
      "processing image testing/fall/48.jpg\n",
      "2\n",
      "processing image testing/fall/49.jpg\n",
      "2\n",
      "processing image testing/fall/59.jpg\n",
      "1\n",
      "processing image testing/fall/71.jpg\n",
      "1\n",
      "processing image testing/fall/64.jpg\n",
      "1\n",
      "processing image testing/fall/8.jpg\n",
      "1\n",
      "processing image testing/fall/66.jpg\n",
      "1\n",
      "processing image testing/fall/99.jpg\n",
      "1\n",
      "processing image testing/fall/98.jpg\n",
      "2\n",
      "processing image testing/fall/73.jpg\n",
      "1\n",
      "processing image testing/fall/67.jpg\n",
      "1\n",
      "processing image testing/fall/9.jpg\n",
      "1\n",
      "processing image testing/fall/14.jpg\n",
      "1\n",
      "processing image testing/fall/28.jpg\n",
      "1\n",
      "processing image testing/fall/101.jpg\n",
      "1\n",
      "processing image testing/fall/115.jpg\n",
      "1\n",
      "processing image testing/fall/17.jpg\n",
      "1\n",
      "processing image testing/fall/116.jpg\n",
      "1\n",
      "processing image testing/fall/103.jpg\n",
      "1\n",
      "processing image testing/fall/117.jpg\n",
      "1\n",
      "processing image testing/fall/16.jpg\n",
      "1\n",
      "processing image testing/fall/12.jpg\n",
      "1\n",
      "processing image testing/fall/113.jpg\n",
      "1\n",
      "processing image testing/fall/107.jpg\n",
      "1\n",
      "processing image testing/fall/106.jpg\n",
      "1\n",
      "processing image testing/fall/13.jpg\n",
      "1\n",
      "processing image testing/fall/39.jpg\n",
      "1\n",
      "processing image testing/fall/104.jpg\n",
      "1\n",
      "processing image testing/fall/111.jpg\n",
      "1\n",
      "processing image testing/fall/105.jpg\n",
      "1\n",
      "processing image testing/fall/10.jpg\n",
      "1\n",
      "processing image testing/fall/38.jpg\n",
      "1\n",
      "processing image testing/fall/21.jpg\n",
      "1\n",
      "processing image testing/fall/35.jpg\n",
      "1\n",
      "processing image testing/fall/108.jpg\n",
      "2\n",
      "processing image testing/fall/120.jpg\n",
      "2\n",
      "processing image testing/fall/109.jpg\n",
      "1\n",
      "processing image testing/fall/34.jpg\n",
      "1\n",
      "processing image testing/fall/20.jpg\n",
      "1\n",
      "processing image testing/fall/36.jpg\n",
      "1\n",
      "processing image testing/fall/122.jpg\n",
      "1\n",
      "processing image testing/fall/23.jpg\n",
      "1\n",
      "processing image testing/fall/26.jpg\n",
      "2\n",
      "processing image testing/fall/32.jpg\n",
      "1\n",
      "processing image testing/fall/30.jpg\n",
      "1\n",
      "processing image testing/fall/125.jpg\n",
      "1\n",
      "processing image testing/fall/119.jpg\n",
      "1\n",
      "processing image testing/fall/118.jpg\n",
      "1\n",
      "processing image testing/fall/31.jpg\n",
      "1\n",
      "processing image testing/fall/25.jpg\n",
      "1\n",
      "processing image testing/fall/19.jpg\n",
      "1\n",
      "processing image testing/fall/42.jpg\n",
      "2\n",
      "processing image testing/fall/4.jpg\n",
      "1\n",
      "processing image testing/fall/56.jpg\n",
      "1\n",
      "processing image testing/fall/81.jpg\n",
      "1\n",
      "processing image testing/fall/80.jpg\n",
      "1\n",
      "processing image testing/fall/5.jpg\n",
      "2\n",
      "processing image testing/fall/57.jpg\n",
      "1\n",
      "processing image testing/fall/43.jpg\n",
      "1\n",
      "processing image testing/fall/55.jpg\n",
      "1\n",
      "processing image testing/fall/7.jpg\n",
      "1\n",
      "processing image testing/fall/41.jpg\n",
      "1\n",
      "processing image testing/fall/96.jpg\n",
      "1\n",
      "processing image testing/fall/82.jpg\n",
      "1\n",
      "processing image testing/fall/83.jpg\n",
      "1\n",
      "processing image testing/fall/68.jpg\n",
      "1\n",
      "processing image testing/fall/40.jpg\n",
      "1\n",
      "processing image testing/fall/54.jpg\n",
      "1\n",
      "processing image testing/fall/6.jpg\n",
      "2\n",
      "processing image testing/fall/87.jpg\n",
      "1\n",
      "processing image testing/fall/45.jpg\n",
      "1\n",
      "processing image testing/fall/51.jpg\n",
      "1\n",
      "processing image testing/fall/79.jpg\n",
      "1\n",
      "processing image testing/fall/53.jpg\n",
      "1\n",
      "processing image testing/fall/1.jpg\n",
      "1\n",
      "processing image testing/fall/84.jpg\n",
      "1\n",
      "processing image testing/fall/90.jpg\n",
      "1\n",
      "processing image testing/fall/91.jpg\n",
      "1\n",
      "processing image testing/fall/52.jpg\n",
      "1\n",
      "Time taken: 2.673593044281006\n"
     ]
    }
   ],
   "source": [
    "#testing falling (binary)\n",
    "t = time.time()\n",
    "print(\"Time at start: \" + str((time.time() - t)))\n",
    "fallingResult = getAllImages('testing/fall')\n",
    "print(\"Time taken: \" + str((time.time() - t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 83 falling images\n",
      "fall: 72 86.74698795180723%\n",
      "onFeet: 11 13.253012048192772%\n"
     ]
    }
   ],
   "source": [
    "#displaying results of falling\n",
    "calcPercentage('falling', fallingResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time at start: 5.1021575927734375e-05\n",
      "processing image testing/onFeet/63.jpg\n",
      "2\n",
      "processing image testing/onFeet/77.jpg\n",
      "1\n",
      "processing image testing/onFeet/162.jpg\n",
      "2\n",
      "processing image testing/onFeet/62.jpg\n",
      "2\n",
      "processing image testing/onFeet/60.jpg\n",
      "2\n",
      "processing image testing/onFeet/149.jpg\n",
      "2\n",
      "processing image testing/onFeet/161.jpg\n",
      "2\n",
      "processing image testing/onFeet/160.jpg\n",
      "2\n",
      "processing image testing/onFeet/148.jpg\n",
      "2\n",
      "processing image testing/onFeet/49.jpg\n",
      "2\n",
      "processing image testing/onFeet/61.jpg\n",
      "2\n",
      "processing image testing/onFeet/59.jpg\n",
      "2\n",
      "processing image testing/onFeet/71.jpg\n",
      "2\n",
      "processing image testing/onFeet/65.jpg\n",
      "2\n",
      "processing image testing/onFeet/158.jpg\n",
      "2\n",
      "processing image testing/onFeet/159.jpg\n",
      "2\n",
      "processing image testing/onFeet/64.jpg\n",
      "1\n",
      "processing image testing/onFeet/70.jpg\n",
      "2\n",
      "processing image testing/onFeet/58.jpg\n",
      "2\n",
      "processing image testing/onFeet/8.jpg\n",
      "1\n",
      "processing image testing/onFeet/66.jpg\n",
      "2\n",
      "processing image testing/onFeet/72.jpg\n",
      "2\n",
      "processing image testing/onFeet/73.jpg\n",
      "1\n",
      "processing image testing/onFeet/67.jpg\n",
      "2\n",
      "processing image testing/onFeet/9.jpg\n",
      "2\n",
      "processing image testing/onFeet/28.jpg\n",
      "2\n",
      "processing image testing/onFeet/29.jpg\n",
      "2\n",
      "processing image testing/onFeet/12.jpg\n",
      "2\n",
      "processing image testing/onFeet/13.jpg\n",
      "2\n",
      "processing image testing/onFeet/39.jpg\n",
      "2\n",
      "processing image testing/onFeet/11.jpg\n",
      "2\n",
      "processing image testing/onFeet/10.jpg\n",
      "2\n",
      "processing image testing/onFeet/38.jpg\n",
      "2\n",
      "processing image testing/onFeet/21.jpg\n",
      "2\n",
      "processing image testing/onFeet/35.jpg\n",
      "2\n",
      "processing image testing/onFeet/34.jpg\n",
      "2\n",
      "processing image testing/onFeet/20.jpg\n",
      "2\n",
      "processing image testing/onFeet/36.jpg\n",
      "2\n",
      "processing image testing/onFeet/22.jpg\n",
      "2\n",
      "processing image testing/onFeet/23.jpg\n",
      "2\n",
      "processing image testing/onFeet/33.jpg\n",
      "1\n",
      "processing image testing/onFeet/27.jpg\n",
      "2\n",
      "processing image testing/onFeet/32.jpg\n",
      "2\n",
      "processing image testing/onFeet/18.jpg\n",
      "2\n",
      "processing image testing/onFeet/24.jpg\n",
      "2\n",
      "processing image testing/onFeet/30.jpg\n",
      "2\n",
      "processing image testing/onFeet/31.jpg\n",
      "1\n",
      "processing image testing/onFeet/25.jpg\n",
      "2\n",
      "processing image testing/onFeet/19.jpg\n",
      "2\n",
      "processing image testing/onFeet/42.jpg\n",
      "2\n",
      "processing image testing/onFeet/56.jpg\n",
      "2\n",
      "processing image testing/onFeet/143.jpg\n",
      "2\n",
      "processing image testing/onFeet/157.jpg\n",
      "2\n",
      "processing image testing/onFeet/156.jpg\n",
      "2\n",
      "processing image testing/onFeet/80.jpg\n",
      "2\n",
      "processing image testing/onFeet/5.jpg\n",
      "2\n",
      "processing image testing/onFeet/57.jpg\n",
      "2\n",
      "processing image testing/onFeet/43.jpg\n",
      "2\n",
      "processing image testing/onFeet/55.jpg\n",
      "2\n",
      "processing image testing/onFeet/41.jpg\n",
      "2\n",
      "processing image testing/onFeet/69.jpg\n",
      "2\n",
      "processing image testing/onFeet/154.jpg\n",
      "2\n",
      "processing image testing/onFeet/155.jpg\n",
      "2\n",
      "processing image testing/onFeet/68.jpg\n",
      "2\n",
      "processing image testing/onFeet/40.jpg\n",
      "2\n",
      "processing image testing/onFeet/54.jpg\n",
      "2\n",
      "processing image testing/onFeet/6.jpg\n",
      "2\n",
      "processing image testing/onFeet/78.jpg\n",
      "2\n",
      "processing image testing/onFeet/2.jpg\n",
      "2\n",
      "processing image testing/onFeet/50.jpg\n",
      "2\n",
      "processing image testing/onFeet/44.jpg\n",
      "2\n",
      "processing image testing/onFeet/151.jpg\n",
      "2\n",
      "processing image testing/onFeet/145.jpg\n",
      "2\n",
      "processing image testing/onFeet/144.jpg\n",
      "2\n",
      "processing image testing/onFeet/150.jpg\n",
      "2\n",
      "processing image testing/onFeet/45.jpg\n",
      "2\n",
      "processing image testing/onFeet/3.jpg\n",
      "2\n",
      "processing image testing/onFeet/51.jpg\n",
      "2\n",
      "processing image testing/onFeet/79.jpg\n",
      "1\n",
      "processing image testing/onFeet/47.jpg\n",
      "2\n",
      "processing image testing/onFeet/53.jpg\n",
      "2\n",
      "processing image testing/onFeet/1.jpg\n",
      "2\n",
      "processing image testing/onFeet/146.jpg\n",
      "2\n",
      "processing image testing/onFeet/152.jpg\n",
      "2\n",
      "processing image testing/onFeet/147.jpg\n",
      "2\n",
      "processing image testing/onFeet/52.jpg\n",
      "2\n",
      "processing image testing/onFeet/46.jpg\n",
      "2\n",
      "Time taken: 3.2476699352264404\n"
     ]
    }
   ],
   "source": [
    "#testing falling (binary)\n",
    "t = time.time()\n",
    "print(\"Time at start: \" + str((time.time() - t)))\n",
    "onFeetResult = getAllImages('testing/onFeet')\n",
    "print(\"Time taken: \" + str((time.time() - t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 87 onFeet images\n",
      "fall: 7 8.045977011494253%\n",
      "onFeet: 80 91.95402298850574%\n"
     ]
    }
   ],
   "source": [
    "#displaying results of falling\n",
    "calcPercentage('onFeet', onFeetResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "def detectAllPlayers():\n",
    "    path = 'players/player'\n",
    "    detected_poses = []\n",
    "    player = 0\n",
    "    pose = 0\n",
    "    #to check if the player exists\n",
    "    playerExists = os.path.isfile(path+str(player)+'.jpg') \n",
    "\n",
    "    while playerExists:\n",
    "        pose = predictPose(path+str(player)+'.jpg')\n",
    "        detected_poses.append(pose)\n",
    "        player +=1\n",
    "        playerExists = os.path.isfile(path+str(player)+'.jpg')   \n",
    "\n",
    "    return detected_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game play\n",
    "def simonSays(correctPose):\n",
    "    playerPoses = detectAllPlayers()\n",
    "    for player in range(len(playerPoses)):\n",
    "        if playerPoses[player] == correctPose:\n",
    "            print(\"Player\", player, \"congrats! You've done the pose correctly\")\n",
    "        else:\n",
    "            print(\"Player\", player, \"uh-oh! You've done the pose incorrectly\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
