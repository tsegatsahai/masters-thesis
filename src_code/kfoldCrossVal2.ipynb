{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "positive-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.utils.np_utils.to_categorical(y, num_classes=None, dtype='float32')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "tf.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47684bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPose(imageName, new_model):\n",
    "    #resize the image since the model is trained with 150 by 150 images\n",
    "    pose = image.load_img(imageName, target_size=(150,150))\n",
    "    pose = image.img_to_array(pose)\n",
    "    pose = np.expand_dims(pose, axis=0)\n",
    "    pose = pose/255\n",
    "    \n",
    "    #actual classification\n",
    "    prediction_prob = new_model.predict(pose)\n",
    "    #returns which pose\n",
    "    poseNumber = new_model.predict_classes(pose)\n",
    "    return poseNumber[0]+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e5e269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSensitivitySpecifity(rootdir, char):\n",
    "    path, dirs, files = next(os.walk(rootdir))\n",
    "    action = 0\n",
    "    actionList = []\n",
    "    falsePositive = 0.0\n",
    "    truePositive = 0.0\n",
    "    falseNegative = 0.0\n",
    "    trueNegative = 0.0\n",
    "    catagory = 0\n",
    "    \n",
    "    if char == 'f':\n",
    "        catagory = 1\n",
    "    elif char == 'o':\n",
    "        catagory = 2\n",
    "    elif char == 's':\n",
    "        catagory = 3\n",
    "  \n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            filepath = subdir + os.sep + file\n",
    "            if filepath.endswith(\".jpg\"):                \n",
    "                #using the model to classify \n",
    "                action = predictPose(filepath)\n",
    "                if action == catagory and file[0] == char: #true positive\n",
    "                    print(\"classified\", file, \"as\", action, \": true positive\")\n",
    "                    truePositive += 1\n",
    "                elif action == catagory and file[0] != char: #false positive\n",
    "                    print(\"classified\", file, \"as\", action, \": false positive\")\n",
    "                    falsePositive += 1\n",
    "                elif action != catagory and file[0] != char: #true negative\n",
    "                    print(\"classified\", file, \"as\", action, \": true negative\")\n",
    "                    trueNegative += 1\n",
    "                elif action != catagory and file[0] == char: #fasle negative\n",
    "                    print(\"classified\", file, \"as\", action, \": false negative\")\n",
    "                    falseNegative += 1\n",
    "                else:\n",
    "                    print(\"ERROR: Unknown Classification\")\n",
    "\n",
    "    print(\"--------------\\n\")\n",
    "    print(\"True Positive for \" + char + \" : \" + str(truePositive))\n",
    "    print(\"False Positive for \" + char + \" : \" + str(falsePositive))\n",
    "    print(\"True Negative for \" + char + \" : \" + str(trueNegative))\n",
    "    print(\"False Negative for \" + char + \" : \" + str(falseNegative))\n",
    "\n",
    "    sensitivity = truePositive/(truePositive+falseNegative)\n",
    "    specifity = trueNegative/(falsePositive+trueNegative)\n",
    "    accuracy = (truePositive+trueNegative)/(trueNegative+truePositive+falseNegative+falsePositive)\n",
    "\n",
    "    print(\"\\nSensitivity: \", sensitivity)\n",
    "    print(\"Specificity: \", specifity)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "    actionList.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mobile-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('classification.csv', dtype=str)\n",
    "#data = pd.read_csv('./Hand_Annotations_2.csv',dtype=str,names=colnames\n",
    "Y = train_data[['label']]\n",
    "\n",
    "kf = KFold(n_splits = 3)\n",
    "                         \n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "image_shape = (150,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emotional-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(#width_shift_range=0.1,\n",
    "                         #height_shift_range=0.1,\n",
    "                         #zoom_range=0.3,\n",
    "                         fill_mode='nearest',\n",
    "                         horizontal_flip = True)\n",
    "                         #rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impaired-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "diagnostic-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "# Here we say randomly turn off 50% of neurons.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Last layer, not binary!\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #not binary for the poses\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b891606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81909d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_generator(train_data, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "developmental-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 583 validated image filenames belonging to 3 classes.\n",
      "Found 292 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/2\n",
      "37/37 [==============================] - 8s 200ms/step - loss: 2.9923 - accuracy: 0.7804 - false_positives: 371.0000 - val_loss: 0.5068 - val_accuracy: 0.8630 - val_false_positives: 131.0000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86301, saving model to kfoldModels/model_1.h5\n",
      "Epoch 2/2\n",
      "37/37 [==============================] - 7s 203ms/step - loss: 0.3959 - accuracy: 0.9091 - false_positives: 327.0000 - val_loss: 0.8400 - val_accuracy: 0.8082 - val_false_positives: 177.0000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.86301\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.4406 - accuracy: 0.8767 - false_positives: 133.0000\n",
      "Found 583 validated image filenames belonging to 3 classes.\n",
      "Found 292 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/2\n",
      "37/37 [==============================] - 8s 201ms/step - loss: 1.3601 - accuracy: 0.8045 - false_positives: 352.0000 - val_loss: 0.2510 - val_accuracy: 0.8904 - val_false_positives: 142.0000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89041, saving model to kfoldModels/model_2.h5\n",
      "Epoch 2/2\n",
      "37/37 [==============================] - 7s 194ms/step - loss: 0.3667 - accuracy: 0.9005 - false_positives: 327.0000 - val_loss: 0.2168 - val_accuracy: 0.9247 - val_false_positives: 136.0000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.89041 to 0.92466, saving model to kfoldModels/model_2.h5\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.2096 - accuracy: 0.9315 - false_positives: 121.0000\n",
      "Found 584 validated image filenames belonging to 3 classes.\n",
      "Found 291 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/2\n",
      "37/37 [==============================] - 8s 195ms/step - loss: 0.5239 - accuracy: 0.8767 - false_positives: 354.0000 - val_loss: 0.1322 - val_accuracy: 0.9450 - val_false_positives: 112.0000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.94502, saving model to kfoldModels/model_3.h5\n",
      "Epoch 2/2\n",
      "37/37 [==============================] - 7s 192ms/step - loss: 0.4030 - accuracy: 0.9041 - false_positives: 328.0000 - val_loss: 0.2190 - val_accuracy: 0.9175 - val_false_positives: 179.0000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.94502\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2322 - accuracy: 0.9347 - false_positives: 113.0000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = 'kfoldModels/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(875),Y):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, target_size=image_shape[:2],\n",
    "                               batch_size = 16,\n",
    "                               x_col = \"filename\", y_col = \"label\",\n",
    "                               class_mode = \"categorical\", shuffle = True)\n",
    "    valid_data_generator  = idg.flow_from_dataframe(validation_data, target_size=image_shape[:2],\n",
    "                            batch_size = 16,\n",
    "                            x_col = \"filename\", y_col = \"label\",\n",
    "                            class_mode = \"categorical\", shuffle = True)\n",
    "    \n",
    "  \n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    #model = create_new_model()\n",
    "\n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',tf.keras.metrics.FalsePositives()])\n",
    "\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "                            monitor='val_accuracy', verbose=1, \n",
    "                            save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                epochs=2,\n",
    "                #steps_per_epoch=150,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=valid_data_generator)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    #PLOT HISTORY\n",
    "\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(\"kfoldModels/model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    \n",
    "    #calculate sensitivity and specificity \n",
    "    \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold_var += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91cebf",
   "metadata": {},
   "source": [
    "**First 10-Fold Cross Validation Results:**\n",
    "\n",
    "List of Accuracies of the 10 Models: [1.0, 0.98591548204422, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "Average of 99.8591548204422%\n",
    "\n",
    "*This doesn't include the images I used for testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "centered-estate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9090909361839294,\n",
       " 1.0,\n",
       " 0.9545454382896423,\n",
       " 1.0,\n",
       " 0.9886363744735718,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9885057210922241,\n",
       " 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac22119b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.40778470039368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(VALIDATION_ACCURACY)/10) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4aa2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
