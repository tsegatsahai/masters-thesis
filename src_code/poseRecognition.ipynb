{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose1 = cv2.imread('positions/train/pose1/4.jpg')\n",
    "pose1 = cv2.cvtColor(pose1,cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pose1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 480, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"pose1\",pose1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for the model\n",
    "\n",
    "There is too much data for us to read all at once in memory. We can use some built in functions in Keras to automatically process the data, generate a flow of batches from a directory, and also manipulate the images.\n",
    "\n",
    "### Image Manipulation\n",
    "\n",
    "Its usually a good idea to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. We can use the **ImageDataGenerator** to do this automatically for us. Check out the documentation for a full list of all the parameters you can use here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(#rotation_range=30, # rotate the image 30 degrees\n",
    "                               #width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
    "                               #height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
    "                               rescale=1/255, # Rescale the image by normalzing it.\n",
    "                               #shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
    "                               #zoom_range=0.2, # Zoom in by 20% max\n",
    "                               horizontal_flip=True, # Allo horizontal flipping\n",
    "                               #fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3bb2ae10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(image_gen.random_transform(pose1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3be230f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(image_gen.random_transform(pose1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 480, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(image_gen.random_transform(pose1))\n",
    "\n",
    "\n",
    "pose1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating many manipulated images from a directory\n",
    "\n",
    "\n",
    "In order to use .flow_from_directory, you must organize the images in sub-directories. This is an absolute requirement, otherwise the method won't work. The directories should only contain images of one class, so one folder per class of images.\n",
    "\n",
    "Structure Needed:\n",
    "\n",
    "* Image Data Folder\n",
    "    * Class 1\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * Class 2\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * ...\n",
    "    * Class n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.DirectoryIterator at 0xb3bb3e6d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen.flow_from_directory('positions/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_gen.flow_from_directory('positions/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Images\n",
    "\n",
    "Let's have Keras resize all the images to 150 pixels by 150 pixels once they've been manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width,height,channels\n",
    "image_shape = (150,150,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(150,150,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "# Here we say randomly turn off 50% of neurons.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Last layer, not binary!\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #not binary for the poses\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2367616   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,424,323\n",
      "Trainable params: 2,424,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory('positions/train',\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical') #catagoricalnfor the poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory('positions/test',\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pose1': 0, 'pose2': 1, 'pose3': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150/150 [==============================] - 1322s 9s/step - loss: 0.0943 - acc: 0.9628 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(train_image_gen,epochs=1,\n",
    "                              steps_per_epoch=150,\n",
    "                              validation_data=test_image_gen,\n",
    "                             validation_steps=12)\n",
    "#I only ran it for 1 epoch and it worked fine (it had great accuracy!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save('poses1epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9669573198988548]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(results.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('EightPoses.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802, 350, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = cv2.imread('POSE3.jpg')\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "pose_file = 'POSE22.jpg'\n",
    "\n",
    "pose = image.load_img(pose_file, target_size=(150, 150))\n",
    "\n",
    "pose = image.img_to_array(pose)\n",
    "\n",
    "pose = np.expand_dims(pose, axis=0) #so the network can think its a batch of one image\n",
    "pose = pose/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob = new_model.predict(pose)\n",
    "new_model.predict_classes(pose) #it will return either 0,1 or 2 \n",
    "                               #for poses 1,2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3526377e-23 9.9999774e-01 4.9228033e-18 9.8221578e-12 1.7766470e-19\n",
      "  1.5273822e-19 3.9252950e-18 4.9790081e-18]]\n"
     ]
    }
   ],
   "source": [
    "# Output prediction\n",
    "print(prediction_prob) #how sure is it that the image belongs to the array it chose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "#function to classify a pose\n",
    "def predictPose(imageName):\n",
    "    #resize the image since the model is trained with 150 by 150 images\n",
    "    pose = image.load_img(imageName, target_size=(150,150))\n",
    "    pose = image.img_to_array(pose)\n",
    "    pose = np.expand_dims(pose, axis=0)\n",
    "    pose = pose/255\n",
    "    \n",
    "    #actual classification\n",
    "    prediction_prob = new_model.predict(pose)\n",
    "    #returns which pose\n",
    "    poseNumber = new_model.predict_classes(pose)\n",
    "    #print(prediction_prob)\n",
    "    return poseNumber[0]+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#sample run\n",
    "print(predictPose('POSE22.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "def detectAllPlayers():\n",
    "    path = 'players/player'\n",
    "    detected_poses = []\n",
    "    player = 0\n",
    "    pose = 0\n",
    "    #to check if the player exists\n",
    "    playerExists = os.path.isfile(path+str(player)+'.jpg') \n",
    "\n",
    "    while playerExists:\n",
    "        pose = predictPose(path+str(player)+'.jpg')\n",
    "        detected_poses.append(pose)\n",
    "        player +=1\n",
    "        playerExists = os.path.isfile(path+str(player)+'.jpg')   \n",
    "\n",
    "    return detected_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 0 is displaying pose 2\n",
      "Player 1 is displaying pose 6\n",
      "Player 2 is displaying pose 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for player in range(len(detectAllPlayers())):\n",
    "    print(\"Player\", player, \"is displaying pose\", detected_poses[player])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game play\n",
    "def simonSays(correctPose):\n",
    "    playerPoses = detectAllPlayers()\n",
    "    for player in range(len(playerPoses)):\n",
    "        if playerPoses[player] == correctPose:\n",
    "            print(\"Player\", player, \"congrats! You've done the pose correctly\")\n",
    "        else:\n",
    "            print(\"Player\", player, \"uh-oh! You've done the pose incorrectly\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 0 congrats! You've done the pose correctly\n",
      "Player 1 uh-oh! You've done the pose incorrectly\n",
      "Player 2 congrats! You've done the pose correctly\n"
     ]
    }
   ],
   "source": [
    "simonSays(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
